{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"sk-proj-9IcU2xBGEuXieBqbcVb4T3BlbkFJjLWzrcVh1y0AtqhBLhUF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"],temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Temperature : </b>\n",
    "The temperature parameter controls the creativity of the text generated by the OpenAI API. A higher temperature will produce more creative text, while a lower temperature will produce more predictable text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of India\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hugging_face = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm_hugging_face.predict(\"Can you write a poem on Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the city of delhi i love the people i love the food i love the people i love the people i love the people i love the people i love the people i love the people i love the people i love the people i love\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of the India'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of the {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of the USA is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "print(chain.run(\"USA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.predict(prompt_template=prompt_template, text=[\"USA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Combining Multiple Chains Using simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],\n",
    "template = \"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_prompt)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Suggest me some amazing places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm= llm, prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here are some amazing places to visit in Bucharest:\\n\\n1. Palace of Parliament - This massive building is the second largest administrative building in the world and is a must-see for its grand architecture and history.\\n\\n2. Old Town (Centrul Vechi) - This charming area is filled with cobblestone streets, colorful buildings, and plenty of cafes, restaurants, and bars to explore.\\n\\n3. Herastrau Park - This large park is perfect for a relaxing stroll or a picnic. It also has a lake where you can rent boats and enjoy the beautiful scenery.\\n\\n4. Romanian Athenaeum - This stunning concert hall is a symbol of Bucharest and hosts many classical music performances throughout the year.\\n\\n5. Village Museum (Muzeul Satului) - This open-air museum showcases traditional Romanian village life with over 300 authentic buildings and exhibits.\\n\\n6. National Museum of Art of Romania - This museum houses an impressive collection of Romanian and European art, including works by famous artists such as Rembrandt and Monet.\\n\\n7. Cismigiu Gardens - This picturesque park is the oldest and largest in Bucharest, with beautiful gardens, a lake, and plenty of benches to relax on.\\n\\n8. Stavropoleos Church - This small,'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"Romania\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"],\n",
    "template = \"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_template, output_key=\"capital\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "                                 template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template,output_key=\"Places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[capital_chain, famous_chain], \n",
    "                        input_variables = ['country'], \n",
    "                        output_variables=['capital',\"Places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Thiland',\n",
       " 'capital': '\\n\\nThe capital of Thailand is Bangkok.',\n",
       " 'Places': ' Here are some amazing places to visit in Bangkok:\\n\\n1. Grand Palace - This iconic landmark is a must-visit for its stunning architecture and rich history. It was the official residence of the Kings of Siam and is now used for ceremonial purposes.\\n\\n2. Wat Pho - Also known as the Temple of the Reclining Buddha, this temple is famous for its massive golden statue of a reclining Buddha. It is also a center for traditional Thai massage.\\n\\n3. Chatuchak Weekend Market - With over 8,000 stalls, this is one of the largest markets in the world. You can find everything from clothes and accessories to souvenirs and street food here.\\n\\n4. Chao Phraya River - Take a boat ride along this river to see the city from a different perspective. You can also visit some of the famous temples and landmarks located along the river.\\n\\n5. Khao San Road - This bustling street is a popular spot for backpackers and budget travelers. It is lined with street vendors, bars, and restaurants, making it a great place to experience the local culture.\\n\\n6. Jim Thompson House - This traditional Thai-style house was once the home of an American businessman who helped revive the Thai silk industry. It now serves as a museum showcasing'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"Thiland\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\LLM\\Learning\\Langchain\\New folder\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY'], temperature=0.6, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001E6658F3C10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001E6658F6850>, temperature=0.6, openai_api_key='sk-proj-9IcU2xBGEuXieBqbcVb4T3BlbkFJjLWzrcVh1y0AtqhBLhUF', openai_proxy='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here are some jokes and punchlines related to The Big Bang Theory and Pied Piper TV show:\\n\\n1. Big Bang Theory:\\n- \"Why did Sheldon Cooper bring a ladder to the bar? He heard the drinks were on the house!\"\\n- \"Knock, knock. Penny. Knock, knock. Penny. Knock, knock. Penny. Bazinga! Sheldon\\'s favorite knock-knock joke.\"\\n- \"Why did Howard Wolowitz become an astronaut? He wanted to boldly go where no man has gone before... except for his mother\\'s house.\"\\n\\n2. Pied Piper (from the show Silicon Valley):\\n- \"Why did the Pied Piper team break up? Because they couldn\\'t handle the high frequency of data compression drama!\"\\n- \"How many software engineers does it take to change a lightbulb? None, they\\'ll just pivot to a more efficient way of living in the dark, like the Pied Piper team.\"\\n- \"What do you call it when Pied Piper\\'s algorithm goes haywire? A data meltdown that even Richard Hendricks can\\'t debug!\"\\n\\nI hope you enjoy these jokes!', response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 36, 'total_tokens': 257}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-9595d9a5-4ed2-4267-86fe-160554bfca62-0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a nerd AI assitant\"),\n",
    "    HumanMessage(content=\"Please provide some Big Bang Theory TV Show and Pied Piper tv show jokes and punchlines.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseprateoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return ', '.join(text.strip().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the use given any input, you should generate 5 synonames words which are seperated by comma.\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([(\"system\",template),\n",
    "                                               (\"human\",human_template)                                               \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseprateoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'refined,  elegant,  advanced,  cultured,  classy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"sophisticated\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
